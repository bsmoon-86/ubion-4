{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 상대경로 / 절대경로\n",
    "1. 절대경로\n",
    "    * 절대적인 주소 \n",
    "    * 환경에 상관없이 고정된 위치를 표현\n",
    "    * ex) \"G:\\ubion\\금융 빅데이터 4기\", \"http://www.google.com\"\n",
    "2. 상대경로\n",
    "    * 상대적인 주소\n",
    "    * 현재 작업중인 디렉토리에서 상위, 하위 이동\n",
    "    * `./` : 현재 작업중인 디렉토리\n",
    "    * `../` : 상위 디렉토리\n",
    "    * `./폴더명/` : 하위폴더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sales_df = pd.read_csv(\"../csv/Sales Records.csv\")\n",
    "sales_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치를 체크를 하는 함수 \n",
    "## .isna() 함수를 사용하면 결측치 값은 True, 결측치가 아니면 False\n",
    "## .isna().sum() 함수를 이용하면 결측치의 개수를 확인 가능(True = 1, False = 0)\n",
    "sales_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 통계 요약 정보를 확인하는 함수\n",
    "## describe() 함수를 사용하면 데이터의 개수, \n",
    "## 평균, 표준편차, 최소값, 최대값, 1사분위, 중앙값, 3사분위 값을 확인이 가능\n",
    "## 데이터가 숫자형태인 데이터에만 적용\n",
    "sales_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬럼의 이름을 변경을 하는 방법\n",
    "## 데이터프레임명.columns = [변경할 컬럼의 이름]\n",
    "sales_df.columns = [\"권역\", \"국가\", \"상품종류\", \"판매채널\", \"우선순위\", \"주문일자\", \n",
    "                    \"주문ID\", \"발송일자\", \"판매단위\", \"단가\", \"원가\", \"총수익\", \"총비용\", \n",
    "                    \"총이윤\"]\n",
    "sales_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬럼의 데이터형태를 datetime 형태로 변경하는 함수. \n",
    "## pandas에 내장된 함수 : to_datetime(데이터프레임[컬럼명], format=데이터의 형태)\n",
    "sales_df[\"주문일자\"] = pd.to_datetime(sales_df[\"주문일자\"], format=\"%m/%d/%Y\")\n",
    "sales_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터의 정렬 방식 변경을 하는 함수(기본값은 오름차순 정렬)\n",
    "## sort_values([컬럼명])\n",
    "# sales_df.sort_values(\"판매단위\")    ## 오름차순 정렬\n",
    "sales_df.sort_values(\"국가\", ascending=False)  \n",
    "## ascending 속성은 False 내림차순 True 오름차순(기본값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터정렬의 기준이 여러개 인 경우\n",
    "sales_df.sort_values([\"국가\", \"판매단위\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터프레임에서 인덱스나 컬럼을 삭제하는 함수\n",
    "## drop(특정값, axis=n) -> n은 축의 방향 : 0 = 행 / 1 = 열\n",
    "\n",
    "## 특정 컬럼을 삭제\n",
    "sales_df.drop([\"발송일자\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 특정 행을 삭제\n",
    "sales_df.drop([1], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 원본의 데이터를 지금까지 유지하고 출력.\n",
    "## 원본 데이터를 수정하는 속성이 존재. \n",
    "## inplace = True : 기존이 되는 원본 데이터를 변경. False가 기본값\n",
    "sales_df.drop([\"발송일자\"], axis = 1, inplace=True)\n",
    "## 출력값이 나오지 않는 이유는?\n",
    "## sales_df = sales_df.drop([\"발송일자\"], axis=1) 동일한 작업임으로 \n",
    "## 변수에 데이터가 할당되었기 때문에 출력값은 나오지 않는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 인덱스의 초기화 하는 함수 \n",
    "## reset_index(drop = n) -> n이 True면 기존의 인덱스가 삭제, \n",
    "## False면 기존의 인덱스는 새로운 컬럼으로 추가\n",
    "## inplace 속성도 가지고 있다. \n",
    "sales_df.reset_index(drop=False) ## 기존의 인덱스를 새로운 컬럼에 유지\n",
    "sales_df.reset_index(drop=True) ## 기존의 인덱스를 삭제"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 파생변수를 생성하는 방법 \n",
    "## 데이터프레임명[파생변수명] = 연산식\n",
    "## 총이윤 컬럼을 삭제하고 다시 연산하여 컬럼을 추가\n",
    "sales_df.drop(\"총이윤\", axis=1, inplace=True)   ##총이윤 컬럼을 삭제하고 원본 데이터에 할당\n",
    "sales_df[\"총 이윤\"] = sales_df[\"총수익\"] - sales_df[\"총비용\"]\n",
    "sales_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## corona.csv 파일 로드 \n",
    "1. `createDt`컬럼을 기준으로 오름차순\n",
    "2. `Unnamed: 0`컬럼을 삭제\n",
    "3. 인덱스의 값을 리셋"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df = pd.read_csv(\"../csv/corona.csv\")\n",
    "#createDt 기준으로 오름차순 정렬\n",
    "corona_df.sort_values(\"createDt\", inplace= True)\n",
    "corona_df.drop(\"Unnamed: 0\", axis=1, inplace=True)\n",
    "corona_df.reset_index(drop=True, inplace=True)\n",
    "corona_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치 확인 \n",
    "corona_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 새로운 파생변수 생성\n",
    "## `decideCnt`의 차이만큼을 일일확진자 컬럼에 추가.\n",
    "## 같은 컬럼의 값의 차이를 넣어주는 방법 2가지 \n",
    "## shift(), diff()\n",
    "# \n",
    "# shift(n) : n값만큼의 인덱스를 이동하여 그 행의 값을 가지고 오는 부분. 기본값은 1\n",
    "# diff() : 한 객체내에서 열과 열 / 행과 행의 차이를 출력\n",
    "\n",
    "corona_df[\"일일확진자\"] = (corona_df[\"decideCnt\"] - corona_df[\"decideCnt\"].shift()).fillna(0)\n",
    "## 첫행의 값은 NaN 결측치로 출력이 된다. \n",
    "## 이유는 전의 행의 값이 존재하지 않아서 연산이 불가능하기 때문\n",
    "## 연산 후 결측치의 값을 채워주는 함수.\n",
    "## fillna(값) : 결측치의 값에 채워주는 부분\n",
    "corona_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df[\"일일사망자\"] = corona_df[\"deathCnt\"].diff().fillna(0)\n",
    "corona_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fillna() \n",
    "# ()안의 숫자형태나 문자형태의 데이터를 넣으면 결측치인 부분이 삽입\n",
    "# method = ('ffill', 'bfill')\n",
    "# ffill : 전의 행의 값이 존재하면 그 값으로 결측치를 채워준다. \n",
    "# bfill : 후의 행의 값이 존재하면 그 값으로 결측치를 채워준다. \n",
    "corona_df.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corona_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##corona 데이터는 누적의심자, 누적확진률 컬럼의 결측치가 존재.\n",
    "## tail 확인했을때 마지막이 값이 존재하지 않는다. \n",
    "## ffill을 사용해서 전의 행의 값을 가지고와서 결측치를 채워보는 예제\n",
    "corona_df[\"accExamCnt\"].fillna(method=\"ffill\").tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## apply 함수\n",
    "## 컬럼에 있는 각 원소들에 연산을 해주는 함수.\n",
    "## lambda 함수\n",
    "## 표현식을 한줄로 처리하기위해 사용하는 함수\n",
    "\n",
    "## 외부 함수를 이용하여 apply() 사용할 때\n",
    "## 데이터프레임[컬럼].apply(외부함수명) : 인자값을 넣지 않는다. \n",
    "## apply, lambda 함수를 같이 사용하는 경우\n",
    "## 데이터프레임[컬럼].apply(lambda x : 표현식)\n",
    "\n",
    "## 누적확진률을 기준으로 1.55보다 높으면 `High` 낮으면 `Low` 값을 가지는 파생변수 `H/L`\n",
    "\n",
    "## 외부 함수를 이용하여 apply()\n",
    "def H_and_L(x):\n",
    "    if x > 1.55:\n",
    "        return \"High\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "corona_df[\"H/L\"] = corona_df[\"accDefRate\"].apply(H_and_L)\n",
    "\n",
    "## apply lambda 함수를 같이 사용하는 경우\n",
    "corona_df[\"H/L\"] = corona_df[\"accDefRate\"].apply(lambda x : \"High\" if (x > 1.55) else \"Low\")\n",
    "corona_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 컬럼의 값들이 빈도수를 체크하는 함수\n",
    "## value_counts()\n",
    "corona_df[\"H/L\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## csv 파일을 4개를 로드 \n",
    "1. transaction_1, transaction_2 데이터프레임을 결합(단순 행 추가 결합)\n",
    "2. transaction_detail_1, transaction_detail_2, 데이터프레임을 결합(행 추가 결합)\n",
    "3. 1,2번 과정에서 결합된 데이터프레임을 조인 결합"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_1 = pd.read_csv(\"../csv/transaction_1.csv\")\n",
    "transaction_2 = pd.read_csv(\"../csv/transaction_2.csv\")\n",
    "transaction_detail_1 = pd.read_csv(\"../csv/transaction_detail_1.csv\")\n",
    "transaction_detail_2 = pd.read_csv(\"../csv/transaction_detail_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 단순 행 추가하는 결합 사용하는 함수\n",
    "## concat()\n",
    "## axis=n : n이 0이면 행 1이면 열 추가 (기본값은 행을 추가)\n",
    "## 단순하게 행이나 열을 합치는 기능\n",
    "## 단순하게 결합 index도 그대로 유지. ignore_index 속성을 이용해서 인덱스의 값을 초기화\n",
    "transaction = pd.concat([transaction_1, transaction_2], ignore_index=True)\n",
    "transaction.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_detail = pd.concat([transaction_detail_1, transaction_detail_2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 조인 결합을 이용해서 두 데이터프레임을 합치는 함수\n",
    "## merge()\n",
    "## 특정한 조건을 기준으로 열을 추가해주는 함수\n",
    "## on 속성은 합쳐질 데이터프레임에 조건을 넣어주는 부분. \n",
    "## 컬럼의 값들이 같은 경우 열을 추가해준다. \n",
    "## on 속성에는 컬럼명을 적어주는 부분\n",
    "## how 속성은 기준이 되는 데이터프레임을 지정\n",
    "## left, right, inner, outer 값들은 지정할 수 있다. \n",
    "join_data = pd.merge(transaction, transaction_detail, on='transaction_id', how='left')\n",
    "## transaction과 transaction_detail 조인결합 기준은 left 조건은 transaction_id값이 같은 경우\n",
    "join_data.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. item_master 파일을 로드해서 join_data 조인결합 (left 기준은 join_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_master = pd.read_csv(\"../csv/item_master.csv\")\n",
    "item_master.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data = pd.merge(join_data, item_master, on='item_id', how='left')\n",
    "total_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## datetime 형 데이터에서 부분만 추출하는 방법\n",
    "## payment_date 컬럼의 데이터 형태를 datetime 변경\n",
    "## 파생변수 payment_month 생성 년과 월만 추출한 데이터를 삽입\n",
    "## to_datetime()을 사용할 값이 datetime형태의 문자열이라면 format을 생략할 수 있다. \n",
    "total_data[\"payment_date\"] = pd.to_datetime(total_data[\"payment_date\"])\n",
    "\n",
    "## 파생변수 생성\n",
    "## .dt.strftime() 함수는 datetime형태에서만 사용이 가능\n",
    "total_data[\"payment_month\"] = total_data[\"payment_date\"].dt.strftime(\"%Y%m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## payment_month을 기준으로 그룹화\n",
    "## 월별 가격의 합계를 구하는 데이터프레임 출력\n",
    "## 그룹화 하는 함수 \n",
    "## groupby()\n",
    "total_data.groupby(\"payment_month\").sum()[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 다중 그룹화\n",
    "total_data.groupby([\"payment_month\", \"item_name\"]).sum()[\"price\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 그룹화한 데이터에서 합계 만이 아니라 평균, 최소, 최대 값을 같이 출력하는 방법\n",
    "## sum 합계, mean 평균, min 최소값, max 최대값\n",
    "## 4개를 동시에 다 보여주려면?\n",
    "## groupby().agg(['mean', 'sum', 'min', 'max])\n",
    "total_data.groupby(\"payment_month\").agg(['mean', 'sum', 'min', 'max'])[\"price\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## drinks.csv 파일 로드\n",
    "1. 결측치 확인\n",
    "2. continent 컬럼에 결측치가 존재 결측치의 값을 'OT'로 지정\n",
    "3. continent별 wine_servings 컬럼의 평균, 최소, 최대, 합계를 출력\n",
    "4. total_litres_of_pure_alchol 컬럼의 전체 평균보다 continent별 평균이 높은 continent가 어디인지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drinks = pd.read_csv(\"../csv/drinks.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치 확인\n",
    "drinks.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 결측치의 값을 'OT' 지정\n",
    "drinks[\"continent\"] = drinks[\"continent\"].fillna('OT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## continent별 wine_servings컬럼의 평균, 합계, 최소, 최대 출력\n",
    "drinks.groupby('continent').agg(['mean', 'sum', 'min', 'max'])[\"wine_servings\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 전체 술 소비량의 평균\n",
    "total_mean = drinks[\"total_litres_of_pure_alcohol\"].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 대륙별 정체 술 소비량의 평균 출력\n",
    "continent_mean = drinks.groupby('continent').mean()['total_litres_of_pure_alcohol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "continent_mean[continent_mean >= total_mean]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uriage 데이터 로드 \n",
    "1. item_name 데이터가 대/소문자 문제, 공백 문제 -> 그룹화 X -> 규칙성이 있게 데이터 변환\n",
    "2. 결측치가 존재 -> 결측치의 값을 채워준다. \n",
    "3. 상품별로 그룹화 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터의 값에 공백이 존재하는 경우 발생하는 에러 \n",
    "a = {\n",
    "    'name' : ['a', ' a', 'b', ' b'],\n",
    "    'age' : [10, 20, 15, 25]\n",
    "}\n",
    "df = pd.DataFrame(a)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby('name').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 데이터 로드\n",
    "uriage_df = pd.read_csv(\"../csv/uriage.csv\")\n",
    "uriage_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## item_name 데이터를 대문자 변환\n",
    "#case1\n",
    "uriage_df[\"item_name\"] = uriage_df[\"item_name\"].str.upper()\n",
    "#case2\n",
    "uriage_df[\"item_name\"] = uriage_df[\"item_name\"].apply(lambda x : x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## item_name 공백을 삭제\n",
    "#case1\n",
    "uriage_df[\"item_name\"] = uriage_df[\"item_name\"].str.replace(\" \",\"\")\n",
    "#case2\n",
    "uriage_df[\"item_name\"] = uriage_df[\"item_name\"].apply(lambda x : x.replace(\" \", \"\"))\n",
    "\n",
    "## strip() -> 문자열 양 옆의 공백을 삭제\n",
    "## replace(\" \", \"\") -> 공백을 삭제(문자열 사이의 공백도 포함)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uriage_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## item_price 결측치에 item_name으로 그룹화 item_price의 평균 값을 삽입\n",
    "flg_is_null = uriage_df[\"item_price\"].isna()\n",
    "\n",
    "## item_price의 값이 결측치인 경우 item_name의 유니크 값(중복 데이터 삭제)\n",
    "na_list = list(uriage_df.loc[flg_is_null, \"item_name\"].unique())\n",
    "na_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "~flg_is_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## `~` 연산자 -> bool의 형태를 반전\n",
    "for i in na_list:\n",
    "    ## (~flg_is_null)&(uriage_df[\"item_name\"] == i) : 결측치가 아니고 item_name의 값이 na_list 값 중 하나\n",
    "    price = uriage_df.loc[(~flg_is_null)&(uriage_df[\"item_name\"] == i),     \n",
    "                            \"item_price\"].mean()        ## item_price 컬럼을 선택해서 그 값의 평균\n",
    "    ## price 값은 na_list중 하나의 값의 평균 값\n",
    "\n",
    "    ## (flg_is_null)&(uriage_df[\"item_name\"] == i) : 결측치고, item_name의 값이 na_list 값 중 하나\n",
    "    uriage_df.loc[(flg_is_null)&(uriage_df[\"item_name\"] == i), \n",
    "                    \"item_price\"] = price       ## item_price에 price라는 변수를 삽입\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uriage_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uriage_df.loc[uriage_df[\"item_name\"]== \"상품A\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "187f19b7e1a6c9dce315ccb3b0d07c5b7aeed6681cd1ee8ee772db2198b62651"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
